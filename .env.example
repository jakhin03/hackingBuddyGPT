llm.api_key='your-openai-key'
# For Gemini models, use this instead:
# llm.api_key='your-gemini-api-key'
log_db.connection_string='log_db.sqlite3'

# exchange with the IP of your target VM
conn.host='enter-the-private-ip-of-some-vm.local'
conn.hostname='the-hostname-of-the-vm-used-for-root-detection'
conn.port=2222

# exchange with the user for your target VM
conn.username='bob'
#To just use keyauth only, use '' with no space for conn.password 
#Otherwise, insert the password for instance here
conn.password='secret'
#To just use username and password auth only, use '' with no space for conn.keyfilename
#Otherwise, insert the filepath for the keyfile here (for example, '/home/bob/.ssh/sshkey.rsa')
conn.keyfilename=''

# which LLM model to use (can be anything openai supports, or if you use a custom llm.api_url, anything your api provides for the model parameter
# For OpenAI models: gpt-3.5-turbo, gpt-4, gpt-4-turbo, gpt-4o, etc.
# For Gemini models: gemini-pro, gemini-1.5-pro, gemini-1.5-flash
llm.model='gpt-3.5-turbo'
llm.context_size=16385

# how many rounds should this thing go?
max_turns = 20

# The following parameters are only relevant for the usecase rag
# rag_database_folder_name: Name of the folder where the vector store will be saved.
# rag_embedding_provider: The embedding provider to use ('openai' or 'gemini')
# rag_embedding: The name of the embedding model used.
#   - For OpenAI: text-embedding-3-small, text-embedding-3-large, text-embedding-ada-002
#   - For Gemini: models/embedding-001
# openai_api_key: API key for OpenAI (used for embeddings if provider is 'openai')
# gemini_api_key: API key for Gemini (used for embeddings if provider is 'gemini')
# rag_return_token_limit: The upper bound for the RAG output.
rag_database_folder_name = "vetorDB"
rag_embedding_provider = "openai"
rag_embedding = "text-embedding-3-small"
openai_api_key = 'your-openai-key'
gemini_api_key = 'your-gemini-api-key'
rag_return_token_limit = 1000
